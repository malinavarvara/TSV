package processor

import (
	"TSVProcessingService/db/sqlc"
	"TSVProcessingService/internal/config"
	"TSVProcessingService/internal/watcher"
	"bytes"
	"context"
	"database/sql"
	"encoding/csv"
	"fmt"
	"io"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"time"

	"github.com/google/uuid"
)

// Processor –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç TSV —Ñ–∞–π–ª—ã
type Processor struct {
	queries *sqlc.Queries
	config  *config.DirectoryConfig
}

// TSVRow –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ TSV —Ñ–∞–π–ª–∞
type TSVRow struct {
	UnitGuid   uuid.UUID
	Mqtt       sql.NullString
	Invid      sql.NullString
	MsgID      sql.NullString
	Text       sql.NullString
	Context    sql.NullString
	Class      sql.NullString
	Level      sql.NullInt32
	Area       sql.NullString
	Addr       sql.NullString
	Block      sql.NullString
	Type       sql.NullString
	Bit        sql.NullInt32
	InvertBit  sql.NullBool
	LineNumber int32
}

// ProcessingError –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏
type ProcessingError struct {
	LineNumber   sql.NullInt32
	RawLine      sql.NullString
	ErrorMessage string
	FieldName    sql.NullString
}

// NewProcessor —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
func NewProcessor(queries *sqlc.Queries, config *config.DirectoryConfig) *Processor {
	return &Processor{
		queries: queries,
		config:  config,
	}
}

// normalizeTSV –∑–∞–º–µ–Ω—è–µ—Ç –¥–≤–∞ –∏ –±–æ–ª–µ–µ –ø—Ä–æ–±–µ–ª–∞ –Ω–∞ —Ç–∞–±—É–ª—è—Ü–∏—é
func normalizeTSV(content []byte) []byte {
	re := regexp.MustCompile(`[ ]{2,}`)
	return re.ReplaceAll(content, []byte("\t"))
}

// ProcessFile –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç TSV —Ñ–∞–π–ª
func (p *Processor) ProcessFile(ctx context.Context, fileInfo watcher.FileInfo) error {
	log.Printf("üîÑ Processing file: %s", fileInfo.Name)

	// 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª—Å—è –ª–∏ —É–∂–µ —Ñ–∞–π–ª
	existingFile, err := p.queries.GetFileByFilename(ctx, fileInfo.Name)
	if err == nil && existingFile.FileHash == fileInfo.Hash {
		log.Printf("File already processed: %s", fileInfo.Name)
		return nil
	}

	// 2. –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ —Ñ–∞–π–ª–µ
	fileParams := sqlc.CreateFileParams{
		Filename: fileInfo.Name,
		FileHash: fileInfo.Hash,
		Status:   sql.NullString{String: "processing", Valid: true},
	}

	file, err := p.queries.CreateFile(ctx, fileParams)
	if err != nil {
		return fmt.Errorf("failed to create file record: %w", err)
	}

	log.Printf("Created file record with ID: %d", file.ID)

	// 3. –ü–∞—Ä—Å–∏–º TSV —Ñ–∞–π–ª
	rows, errors := p.parseTSVFile(fileInfo.Path, file.ID)
	if len(errors) > 0 {
		// –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
		for _, processingErr := range errors {
			errParams := sqlc.CreateProcessingErrorParams{
				FileID:       file.ID,
				LineNumber:   processingErr.LineNumber,
				RawLine:      processingErr.RawLine,
				ErrorMessage: processingErr.ErrorMessage,
				FieldName:    processingErr.FieldName,
			}
			if _, err := p.queries.CreateProcessingError(ctx, errParams); err != nil {
				log.Printf("Error saving processing error: %v", err)
			}
		}
	}

	// 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É
	successCount := int32(0)
	failedCount := int32(0)

	for _, row := range rows {
		deviceDataParams := sqlc.CreateDeviceDataParams{
			FileID:     file.ID,
			UnitGuid:   row.UnitGuid,
			Mqtt:       row.Mqtt,
			Invid:      row.Invid,
			MsgID:      row.MsgID,
			Text:       row.Text,
			Context:    row.Context,
			Class:      row.Class,
			Level:      row.Level,
			Area:       row.Area,
			Addr:       row.Addr,
			Block:      row.Block,
			Type:       row.Type,
			Bit:        row.Bit,
			InvertBit:  row.InvertBit,
			LineNumber: row.LineNumber,
		}

		_, err := p.queries.CreateDeviceData(ctx, deviceDataParams)
		if err != nil {
			log.Printf("Error saving device data: %v", err)
			failedCount++
			continue
		}
		successCount++
	}

	// 5. –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞
	updateParams := sqlc.UpdateFileProgressParams{
		ID:            file.ID,
		RowsProcessed: sql.NullInt32{Int32: successCount, Valid: true},
		RowsFailed:    sql.NullInt32{Int32: failedCount, Valid: true},
	}

	if _, err := p.queries.UpdateFileProgress(ctx, updateParams); err != nil {
		log.Printf("Error updating file progress: %v", err)
	}

	// 6. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
	status := "completed"
	if failedCount > 0 && failedCount == int32(len(rows)) {
		status = "failed"
	} else if failedCount > 0 {
		status = "partial"
	}

	statusParams := sqlc.UpdateFileStatusParams{
		ID:     file.ID,
		Status: sql.NullString{String: status, Valid: true},
	}

	if _, err := p.queries.UpdateFileStatus(ctx, statusParams); err != nil {
		log.Printf("Error updating file status: %v", err)
	}

	// 7. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç—ã
	if err := p.generateReports(ctx, file.ID, rows); err != nil {
		log.Printf("Error generating reports: %v", err)
	}

	log.Printf("‚úÖ Finished processing: %s. Success: %d, Failed: %d",
		fileInfo.Name, successCount, failedCount)

	return nil
}

func (p *Processor) parseTSVFile(filePath string, fileID int64) ([]TSVRow, []ProcessingError) {
	log.Printf("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞: %s", filePath)

	// 1. –ß–∏—Ç–∞–µ–º –≤–µ—Å—å —Ñ–∞–π–ª
	content, err := os.ReadFile(filePath)
	if err != nil {
		log.Printf("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: %v", err)
		return nil, []ProcessingError{{
			ErrorMessage: fmt.Sprintf("failed to read file: %v", err),
		}}
	}

	// 2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –¥–≤–∞+ –ø—Ä–æ–±–µ–ª–∞ -> —Ç–∞–±—É–ª—è—Ü–∏—è
	normalized := normalizeTSV(content)

	// 3. –°–æ–∑–¥–∞—ë–º CSV Reader —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º TAB
	reader := csv.NewReader(bytes.NewReader(normalized))
	reader.Comma = '\t'
	reader.FieldsPerRecord = -1    // —Ä–∞–∑—Ä–µ—à–∞–µ–º —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª–µ–π
	reader.TrimLeadingSpace = true // –æ–±—Ä–µ–∑–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ

	var rows []TSVRow
	var errors []ProcessingError

	lineNumber := int32(0)
	headerSkipped := false

	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			lineNumber++
			log.Printf("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ %d: %v", lineNumber, err)
			errors = append(errors, ProcessingError{
				LineNumber:   sql.NullInt32{Int32: lineNumber, Valid: true},
				ErrorMessage: fmt.Sprintf("CSV read error: %v", err),
			})
			continue
		}

		lineNumber++
		rawLine := strings.Join(record, "\t") // –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

		// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
		if len(record) == 0 || (len(record) == 1 && strings.TrimSpace(record[0]) == "") {
			continue
		}

		// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (—Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å #)
		if len(record) > 0 && strings.HasPrefix(strings.TrimSpace(record[0]), "#") {
			continue
		}

		// –ü–µ—Ä–≤–∞—è –Ω–µ-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫
		if !headerSkipped {
			headerSkipped = true
			log.Printf("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫: %s", rawLine)
			continue
		}

		// –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö
		row, err := p.parseLine(record, lineNumber, rawLine)
		if err != nil {
			log.Printf("‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–æ–∫–∏ %d: %v", lineNumber, err)
			errors = append(errors, ProcessingError{
				LineNumber:   sql.NullInt32{Int32: lineNumber, Valid: true},
				RawLine:      sql.NullString{String: rawLine, Valid: true},
				ErrorMessage: err.Error(),
			})
			continue
		}

		rows = append(rows, row)
		log.Printf("‚úÖ –°—Ç—Ä–æ–∫–∞ %d: unit_guid=%s, msg_id=%v", lineNumber, row.UnitGuid, row.MsgID)
	}

	log.Printf("üìä –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: %d —Å—Ç—Ä–æ–∫, %d –æ—à–∏–±–æ–∫", len(rows), len(errors))
	return rows, errors
}

// parseLine - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
// parseLine –Ω–∞—Ö–æ–¥–∏—Ç UUID –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–ª—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –µ–≥–æ –ø–æ–∑–∏—Ü–∏–∏
func (p *Processor) parseLine(fields []string, lineNumber int32, rawLine string) (TSVRow, error) {
	row := TSVRow{LineNumber: lineNumber}

	// 1. –ò—â–µ–º –ø–æ–ª–µ —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º UUID (unit_guid)
	guidIndex := -1
	var guid uuid.UUID
	var err error
	for i, field := range fields {
		field = strings.TrimSpace(field)
		if field == "" {
			continue
		}
		guid, err = uuid.Parse(field)
		if err == nil {
			guidIndex = i
			break
		}
	}
	if guidIndex == -1 {
		return row, fmt.Errorf("unit_guid (UUID) not found in line")
	}
	row.UnitGuid = guid

	// 2. –ü–æ–ª–µ –ø–µ—Ä–µ–¥ GUID ‚Äî invid (–∏–Ω–≤–µ–Ω—Ç–∞—Ä–Ω—ã–π –Ω–æ–º–µ—Ä)
	if guidIndex-1 >= 0 {
		if val := strings.TrimSpace(fields[guidIndex-1]); val != "" {
			row.Invid = sql.NullString{String: val, Valid: true}
		}
	}

	// 3. –ï—â—ë —Ä–∞–Ω—å—à–µ ‚Äî mqtt (–µ—Å–ª–∏ –µ—Å—Ç—å)
	if guidIndex-2 >= 0 {
		if val := strings.TrimSpace(fields[guidIndex-2]); val != "" && val != row.Invid.String {
			// –ó–∞—â–∏—Ç–∞ –æ—Ç –æ—à–∏–±–æ—á–Ω–æ–≥–æ –∑–∞—Ö–≤–∞—Ç–∞ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫–∏
			row.Mqtt = sql.NullString{String: val, Valid: true}
		}
	}

	// 4. –ü–æ–ª—è –ø–æ—Å–ª–µ GUID ‚Äî —Å—Ç—Ä–æ–≥–æ –ø–æ –ø–æ—Ä—è–¥–∫—É
	if guidIndex+1 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+1]); val != "" {
			row.MsgID = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+2 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+2]); val != "" {
			row.Text = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+3 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+3]); val != "" {
			row.Context = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+4 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+4]); val != "" {
			row.Class = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+5 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+5]); val != "" {
			if level, err := parseLevel(val); err == nil {
				row.Level = sql.NullInt32{Int32: level, Valid: true}
			}
		}
	}
	if guidIndex+6 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+6]); val != "" {
			row.Area = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+7 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+7]); val != "" {
			row.Addr = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+8 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+8]); val != "" {
			row.Block = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+9 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+9]); val != "" {
			row.Type = sql.NullString{String: val, Valid: true}
		}
	}
	if guidIndex+10 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+10]); val != "" {
			if bit, err := parseBit(val); err == nil {
				row.Bit = sql.NullInt32{Int32: bit, Valid: true}
			}
		}
	}
	if guidIndex+11 < len(fields) {
		if val := strings.TrimSpace(fields[guidIndex+11]); val != "" {
			if invert, err := parseInvertBit(val); err == nil {
				row.InvertBit = sql.NullBool{Bool: invert, Valid: true}
			}
		}
	}

	return row, nil
}

// –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
func parseLevel(field string) (int32, error) {
	level, err := strconv.ParseInt(field, 10, 32)
	if err != nil {
		return 0, err
	}
	return int32(level), nil
}

func parseBit(field string) (int32, error) {
	bit, err := strconv.ParseInt(field, 10, 32)
	if err != nil {
		return 0, err
	}
	return int32(bit), nil
}

func parseInvertBit(field string) (bool, error) {
	// –ú–æ–∂–µ—Ç –±—ã—Ç—å "true"/"false", "1"/"0", –∏–ª–∏ "–¥–∞"/"–Ω–µ—Ç"
	field = strings.ToLower(strings.TrimSpace(field))
	switch field {
	case "true", "1", "–¥–∞", "yes":
		return true, nil
	case "false", "0", "–Ω–µ—Ç", "no", "":
		return false, nil
	default:
		// –ü—Ä–æ–±—É–µ–º –∫–∞–∫ —á–∏—Å–ª–æ
		if val, err := strconv.ParseBool(field); err == nil {
			return val, nil
		}
		return false, fmt.Errorf("cannot parse invert_bit: %s", field)
	}
}

// generateReports –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç—ã –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
func (p *Processor) generateReports(ctx context.Context, fileID int64, rows []TSVRow) error {
	// –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ unit_guid
	byUnit := make(map[uuid.UUID][]TSVRow)
	for _, row := range rows {
		byUnit[row.UnitGuid] = append(byUnit[row.UnitGuid], row)
	}

	for guid, data := range byUnit {
		reportPath, err := p.createReport(guid, data)
		if err != nil {
			log.Printf("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–∞ –¥–ª—è %s: %v", guid, err)
			continue
		}

		params := sqlc.CreateReportParams{
			UnitGuid:   guid,
			ReportType: sql.NullString{String: "txt", Valid: true},
			FilePath:   reportPath,
		}
		if _, err := p.queries.CreateReport(ctx, params); err != nil {
			log.Printf("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á—ë—Ç–∞ –≤ –ë–î: %v", err)
		} else {
			log.Printf("‚úÖ –û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: %s", reportPath)
		}
	}
	return nil
}

func (p *Processor) createReport(unitGuid uuid.UUID, data []TSVRow) (string, error) {
	if err := os.MkdirAll(p.config.OutputPath, 0755); err != nil {
		return "", err
	}

	timestamp := time.Now().Format("20060102_150405")
	filename := fmt.Sprintf("%s_%s.txt", unitGuid.String(), timestamp)
	path := filepath.Join(p.config.OutputPath, filename)

	content := p.generateTextReport(unitGuid, data)
	if err := os.WriteFile(path, []byte(content), 0644); err != nil {
		return "", err
	}
	return path, nil
}

func (p *Processor) generateTextReport(unitGuid uuid.UUID, data []TSVRow) string {
	var b strings.Builder
	b.WriteString("Device Report\n")
	b.WriteString("=============\n\n")
	b.WriteString("Unit GUID: " + unitGuid.String() + "\n")
	b.WriteString("Generated: " + time.Now().Format(time.RFC3339) + "\n")
	b.WriteString("Total records: " + fmt.Sprintf("%d", len(data)) + "\n\n")

	b.WriteString("Device Data:\n")
	b.WriteString("------------\n")
	for i, row := range data {
		b.WriteString(fmt.Sprintf("\nRecord %d:\n", i+1))
		if row.MsgID.Valid {
			b.WriteString("  Message ID: " + row.MsgID.String + "\n")
		}
		if row.Text.Valid {
			b.WriteString("  Text: " + row.Text.String + "\n")
		}
		if row.Class.Valid {
			b.WriteString("  Class: " + row.Class.String + "\n")
		}
		if row.Level.Valid {
			b.WriteString("  Level: " + fmt.Sprintf("%d", row.Level.Int32) + "\n")
		}
		if row.Addr.Valid {
			b.WriteString("  Address: " + row.Addr.String + "\n")
		}
	}
	return b.String()
}
